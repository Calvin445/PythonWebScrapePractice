from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import numpy as np
import time
import pandas as pd
from datetime import datetime
startTime = datetime.now()


# Path to my local chromedriver
driver = webdriver.Chrome("C:/Users/wojcean/Desktop/node/chromedriver.exe")

driver.get('https://stats.nba.com/schedule/#!?PD=N&Month=3&TeamID=1610612738')

# Getting all schedule games
schedule = driver.find_elements_by_class_name('schedule-game')


# List of game IDs
game_ids = []

# Getting all game IDs
for element in schedule:
    game_id = element.find_element_by_tag_name('article')
    game_id = game_id.get_attribute('id')[5:]
    game_ids.append(game_id)

ids_df = pd.DataFrame(game_ids)

def scrapeLineup(game_id):
    print("getting lineups of game " + game_id)
    driver.get('https://stats.nba.com/game/' + str(game_id))
    player_tables = driver.find_elements_by_class_name("nba-stat-table__overlay")
    lineups = []
    for table in player_tables:
        players = table.find_elements_by_tag_name('tr')

        starting_five = []
        limit = 6
        count = 0
        for player in players: 
            if count == 0:
                count = count + 1
            elif limit == count:
                break
            else:
                starting_five.append(player.text[:-2])
                count = count + 1
        lineups.append(starting_five)
    return lineups


def scrapePlayByPlay(game_id): 
    print("getting playbyplay of game " + game_id)
    wait = WebDriverWait(driver, 20, poll_frequency=.1)
    driver.get('https://stats.nba.com/game/' + str(game_id) + '/playbyplay/')

    element = wait.until(
        EC.presence_of_all_elements_located((By.CLASS_NAME, 'boxscore-pbp__inner'))
    )

    play_by_play = driver.find_element_by_class_name('boxscore-pbp__inner')
    
    play_by_play = play_by_play.find_element_by_tag_name('tbody')
    play_by_play = play_by_play.find_elements(By.XPATH, "//tr[contains(@id,'play')]")
    print("found all plays ")
    print( datetime.now() - startTime )
    return play_by_play

oneGame = game_ids[0]

result1 = scrapeLineup(oneGame)
print(result1)


plays = []
result = scrapePlayByPlay(oneGame)
current_quarter = ""
index = 0
for item in result: 
    print(index)
    print(item.get_attribute('innerHTML'))
    print()
    play = []
    """
    try:
        htm_play = item.find_element_by_class_name('htm')
        htm_play = htm_play.find_element_by_tag_name('a')
        play.append(htm_play.text)
    except:
        play.append(np.NaN)
        
    try:
        vtm_play = item.find_element_by_class_name('vtm')
        vtm_play = vtm_play.find_element_by_tag_name('a')
        play.append(vtm_play.text)
    except:
        play.append(np.NaN)
    """
    try:
        quarter = item.find_element_by_class_name('start-period')
        play.append(quarter.text[-2:])
        current_quarter = quarter.text[-2:]
    except:
        play.append(current_quarter)
    try:
        time = item.find_element_by_class_name('time')
        play.append(time.text)
    except:
        play.append(np.NaN)
    try:
        score = item.find_element_by_class_name('score')
        play.append(score.text)
    except:
        play.append(np.NaN)    

    plays.append(play)
    index = index + 1

plays_df = pd.DataFrame(plays)

#plays_df.columns = ['home_play', 'away_play', 'quarter', 'time', 'score']

#col = ['quarter', 'score']

#plays_df.loc[:,col] = plays_df.loc[:,col].ffill()


jsonResult = plays_df.to_json(orient='index')
print(datetime.now() - startTime)
